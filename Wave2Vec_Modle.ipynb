{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# src.wav2vec2.config\n",
        "import json\n",
        "import os\n",
        "from dataclasses import asdict, dataclass, field\n",
        "\n",
        "@dataclass\n",
        "class Wav2Vec2Config:\n",
        "  vocab_size: int = 32\n",
        "  dropout: int = 0.1\n",
        "  hidden_size: int = 768\n",
        "  num_heads: int = 12\n",
        "  num_layers: int = 12\n",
        "  intermediate_size: int = 3072\n",
        "  is_gelu_approx: bool = False\n",
        "  layer_norm_eps: float = 1e-5\n",
        "  survival_prob: float = 1.0\n",
        "  pad_id: int = 0\n",
        "\n",
        "\n",
        "  # positional embedding\n",
        "  num_conv_pos_embeddings: int = 128\n",
        "  num_conv_pos_embedding_groups: int = 16\n",
        "\n",
        "  # feature extractor\n",
        "  filter_sizes: list = field(\n",
        "      default_factory=lambda: [512, 512, 512, 512, 512, 512, 512]\n",
        "  )\n",
        "  kernal_sizes: list = field(default_factory=lambda: [10, 3, 3, 3, 3, 2, 2])\n",
        "  strides: list = field(default_factory=lambda: [5, 2, 2, 2, 2, 2, 2])\n",
        "  conv_bias: bool = False\n",
        "\n",
        "  # spec augmentation arguments\n",
        "  apply_spec_augment: bool = True\n",
        "  mask_time_prob: float = 0.05\n",
        "  mask_time_length: int = 10\n",
        "\n",
        "  attention_norm_type: str = \"postnorm\"\n",
        "  feature_extractor_norm_type: bool = \"group\"\n",
        "  is_robust: bool = False\n",
        "\n",
        "  def __post_init__(self):\n",
        "      if not (len(self.filter_sizes) == len(self.kernal_sizes) == len(self.strides)):\n",
        "          raise ValueError(\n",
        "              \"Length of filter_sizes, kernal_sizes, strides must match.\"\n",
        "          )\n",
        "      if self.hidden_size % self.num_heads != 0:\n",
        "          raise ValueError(\"Hidden size must be perfect multiple of num_heads.\")\n",
        "\n",
        "      assert self.feature_extractor_norm_type in [\"group\", \"layer\"], \"Only `group` / `layer` are supported\"\n",
        "      assert self.attention_norm_type in [\"prenorm\", \"postnorm\"], \"Only `prenorm` / `postnorm` are supported\"\n",
        "\n",
        "  def save_pretrained(self, save_dir):\n",
        "      os.makedirs(save_dir, exist_ok=True)\n",
        "      with open(os.path.join(save_dir, \"config.json\"), \"w\") as f:\n",
        "          json.dump(asdict(self), f)\n",
        "\n",
        "  @classmethod\n",
        "  def from_json(cls, path: str):\n",
        "      with open(path, \"r\") as f:\n",
        "          config_dict = json.load(f)\n",
        "      return cls(**config_dict)\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class RobustWav2Vec2Config(Wav2Vec2Config):\n",
        "    attention_norm_type: str = \"prenorm\"\n",
        "    feature_extractor_norm_type: str = \"layer\"\n",
        "    is_robust: bool = True\n",
        "    conv_bias: bool = True\n",
        "\n",
        "    hidden_size: int = 1024\n",
        "    intermediate_size: int = 4096\n",
        "    num_heads: int = 16\n",
        "    num_layers: int = 24"
      ],
      "metadata": {
        "id": "45FqNf9Q2cwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#                                          tensorflow_addons.py\n",
        "import tensorflow as tf\n",
        "from typeguard import typechecked\n",
        "\n",
        "\n",
        "class Conv1DWithWeightNorm(tf.keras.layers.Conv1D):\n",
        "    \"\"\"\n",
        "    Adapted from `tensorflow_addons.layers.WeightNormalization`\n",
        "    torch.nn.WeightNorm works slightly different. So, it's better to implement it\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        self._padding = kwargs.pop(\"padding\")\n",
        "        self.filter_axis = 0\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "    def _compute_kernel(self):\n",
        "        \"\"\"Generate weights with normalization.\"\"\"\n",
        "        self.kernel = (\n",
        "            tf.nn.l2_normalize(self.weight_v, axis=self.kernel_norm_axes)\n",
        "            * self.weight_g\n",
        "        )\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        super().build(input_shape)\n",
        "\n",
        "        kernel_norm_axes = list(range(self.kernel.shape.rank))\n",
        "        kernel_norm_axes.pop(self.filter_axis)\n",
        "        self.kernel_norm_axes = kernel_norm_axes\n",
        "\n",
        "        # renaming kernal variable for making similar to torch-weight-norm\n",
        "        self.kernel = tf.Variable(self.kernel, name=\"weight_v\", trainable=True)\n",
        "        self.weight_v = self.kernel\n",
        "\n",
        "        self._init_weight_g()\n",
        "\n",
        "    def _init_weight_g(self):\n",
        "        \"\"\"Set the norm of the weight vector.\"\"\"\n",
        "        self.weight_g = self.add_weight(\n",
        "            name=\"weight_g\",\n",
        "            shape=(int(self.weight_v.shape[self.filter_axis]), 1, 1),\n",
        "            initializer=\"ones\",\n",
        "            dtype=self.weight_v.dtype,\n",
        "            trainable=True,\n",
        "        )\n",
        "        kernel_norm = tf.sqrt(\n",
        "            tf.reduce_sum(tf.square(self.weight_v), axis=self.kernel_norm_axes)\n",
        "        )\n",
        "        self.weight_g.assign(kernel_norm[:, tf.newaxis, tf.newaxis])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        self._compute_kernel()\n",
        "        output = tf.pad(inputs, ((0, 0), (self._padding, self._padding), (0, 0)))\n",
        "        return super().call(output)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\"padding\": self._padding})\n",
        "        return config\n",
        "\n",
        "\n",
        "# FOLLOWING CODE IS DIRECTLY TAKEN FROM OFFICIAL TENSORFLOW_ADDONS\n",
        "# ITS TAKEN TO MAKE THIS PROJECT INDEPENDENT OF TENSORFLOW VERSION\n",
        "# CURRENTLY, TENSORFLOW_ADDONS DOESN'T WORK WITH TF>=2.5\n",
        "\n",
        "\n",
        "class GroupNormalization(tf.keras.layers.Layer):\n",
        "    \"\"\"Group normalization layer.\n",
        "    Source: \"Group Normalization\" (Yuxin Wu & Kaiming He, 2018)\n",
        "    https://arxiv.org/abs/1803.08494\n",
        "    Group Normalization divides the channels into groups and computes\n",
        "    within each group the mean and variance for normalization.\n",
        "    Empirically, its accuracy is more stable than batch norm in a wide\n",
        "    range of small batch sizes, if learning rate is adjusted linearly\n",
        "    with batch sizes.\n",
        "    Relation to Layer Normalization:\n",
        "    If the number of groups is set to 1, then this operation becomes identical\n",
        "    to Layer Normalization.\n",
        "    Relation to Instance Normalization:\n",
        "    If the number of groups is set to the\n",
        "    input dimension (number of groups is equal\n",
        "    to number of channels), then this operation becomes\n",
        "    identical to Instance Normalization.\n",
        "    Args:\n",
        "        groups: Integer, the number of groups for Group Normalization.\n",
        "            Can be in the range [1, N] where N is the input dimension.\n",
        "            The input dimension must be divisible by the number of groups.\n",
        "            Defaults to 32.\n",
        "        axis: Integer, the axis that should be normalized.\n",
        "        epsilon: Small float added to variance to avoid dividing by zero.\n",
        "        center: If True, add offset of `beta` to normalized tensor.\n",
        "            If False, `beta` is ignored.\n",
        "        scale: If True, multiply by `gamma`.\n",
        "            If False, `gamma` is not used.\n",
        "        beta_initializer: Initializer for the beta weight.\n",
        "        gamma_initializer: Initializer for the gamma weight.\n",
        "        beta_regularizer: Optional regularizer for the beta weight.\n",
        "        gamma_regularizer: Optional regularizer for the gamma weight.\n",
        "        beta_constraint: Optional constraint for the beta weight.\n",
        "        gamma_constraint: Optional constraint for the gamma weight.\n",
        "    Input shape:\n",
        "        Arbitrary. Use the keyword argument `input_shape`\n",
        "        (tuple of integers, does not include the samples axis)\n",
        "        when using this layer as the first layer in a model.\n",
        "    Output shape:\n",
        "        Same shape as input.\n",
        "    \"\"\"\n",
        "\n",
        "    @typechecked\n",
        "    def __init__(\n",
        "        self,\n",
        "        groups: int = 32,\n",
        "        axis: int = -1,\n",
        "        epsilon: float = 1e-3,\n",
        "        center: bool = True,\n",
        "        scale: bool = True,\n",
        "        beta_initializer=\"zeros\",\n",
        "        gamma_initializer=\"ones\",\n",
        "        beta_regularizer=None,\n",
        "        gamma_regularizer=None,\n",
        "        beta_constraint=None,\n",
        "        gamma_constraint=None,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super().__init__(**kwargs)\n",
        "        self.supports_masking = True\n",
        "        self.groups = groups\n",
        "        self.axis = axis\n",
        "        self.epsilon = epsilon\n",
        "        self.center = center\n",
        "        self.scale = scale\n",
        "        self.beta_initializer = tf.keras.initializers.get(beta_initializer)\n",
        "        self.gamma_initializer = tf.keras.initializers.get(gamma_initializer)\n",
        "        self.beta_regularizer = tf.keras.regularizers.get(beta_regularizer)\n",
        "        self.gamma_regularizer = tf.keras.regularizers.get(gamma_regularizer)\n",
        "        self.beta_constraint = tf.keras.constraints.get(beta_constraint)\n",
        "        self.gamma_constraint = tf.keras.constraints.get(gamma_constraint)\n",
        "        self._check_axis()\n",
        "\n",
        "    def build(self, input_shape):\n",
        "\n",
        "        self._check_if_input_shape_is_none(input_shape)\n",
        "        self._set_number_of_groups_for_instance_norm(input_shape)\n",
        "        self._check_size_of_dimensions(input_shape)\n",
        "        self._create_input_spec(input_shape)\n",
        "\n",
        "        self._add_gamma_weight(input_shape)\n",
        "        self._add_beta_weight(input_shape)\n",
        "        self.built = True\n",
        "        super().build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "\n",
        "        input_shape = tf.keras.backend.int_shape(inputs)\n",
        "        tensor_input_shape = tf.shape(inputs)\n",
        "\n",
        "        reshaped_inputs, group_shape = self._reshape_into_groups(\n",
        "            inputs, input_shape, tensor_input_shape\n",
        "        )\n",
        "\n",
        "        normalized_inputs = self._apply_normalization(reshaped_inputs, input_shape)\n",
        "\n",
        "        is_instance_norm = (input_shape[self.axis] // self.groups) == 1\n",
        "        if not is_instance_norm:\n",
        "            outputs = tf.reshape(normalized_inputs, tensor_input_shape)\n",
        "        else:\n",
        "            outputs = normalized_inputs\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            \"groups\": self.groups,\n",
        "            \"axis\": self.axis,\n",
        "            \"epsilon\": self.epsilon,\n",
        "            \"center\": self.center,\n",
        "            \"scale\": self.scale,\n",
        "            \"beta_initializer\": tf.keras.initializers.serialize(self.beta_initializer),\n",
        "            \"gamma_initializer\": tf.keras.initializers.serialize(\n",
        "                self.gamma_initializer\n",
        "            ),\n",
        "            \"beta_regularizer\": tf.keras.regularizers.serialize(self.beta_regularizer),\n",
        "            \"gamma_regularizer\": tf.keras.regularizers.serialize(\n",
        "                self.gamma_regularizer\n",
        "            ),\n",
        "            \"beta_constraint\": tf.keras.constraints.serialize(self.beta_constraint),\n",
        "            \"gamma_constraint\": tf.keras.constraints.serialize(self.gamma_constraint),\n",
        "        }\n",
        "        base_config = super().get_config()\n",
        "        return {**base_config, **config}\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape\n",
        "\n",
        "    def _reshape_into_groups(self, inputs, input_shape, tensor_input_shape):\n",
        "\n",
        "        group_shape = [tensor_input_shape[i] for i in range(len(input_shape))]\n",
        "        is_instance_norm = (input_shape[self.axis] // self.groups) == 1\n",
        "        if not is_instance_norm:\n",
        "            group_shape[self.axis] = input_shape[self.axis] // self.groups\n",
        "            group_shape.insert(self.axis, self.groups)\n",
        "            group_shape = tf.stack(group_shape)\n",
        "            reshaped_inputs = tf.reshape(inputs, group_shape)\n",
        "            return reshaped_inputs, group_shape\n",
        "        else:\n",
        "            return inputs, group_shape\n",
        "\n",
        "    def _apply_normalization(self, reshaped_inputs, input_shape):\n",
        "\n",
        "        group_shape = tf.keras.backend.int_shape(reshaped_inputs)\n",
        "        group_reduction_axes = list(range(1, len(group_shape)))\n",
        "        is_instance_norm = (input_shape[self.axis] // self.groups) == 1\n",
        "        if not is_instance_norm:\n",
        "            axis = -2 if self.axis == -1 else self.axis - 1\n",
        "        else:\n",
        "            axis = -1 if self.axis == -1 else self.axis - 1\n",
        "        group_reduction_axes.pop(axis)\n",
        "\n",
        "        mean, variance = tf.nn.moments(\n",
        "            reshaped_inputs, group_reduction_axes, keepdims=True\n",
        "        )\n",
        "\n",
        "        gamma, beta = self._get_reshaped_weights(input_shape)\n",
        "        normalized_inputs = tf.nn.batch_normalization(\n",
        "            reshaped_inputs,\n",
        "            mean=mean,\n",
        "            variance=variance,\n",
        "            scale=gamma,\n",
        "            offset=beta,\n",
        "            variance_epsilon=self.epsilon,\n",
        "        )\n",
        "        return normalized_inputs\n",
        "\n",
        "    def _get_reshaped_weights(self, input_shape):\n",
        "        broadcast_shape = self._create_broadcast_shape(input_shape)\n",
        "        gamma = None\n",
        "        beta = None\n",
        "        if self.scale:\n",
        "            gamma = tf.reshape(self.gamma, broadcast_shape)\n",
        "\n",
        "        if self.center:\n",
        "            beta = tf.reshape(self.beta, broadcast_shape)\n",
        "        return gamma, beta\n",
        "\n",
        "    def _check_if_input_shape_is_none(self, input_shape):\n",
        "        dim = input_shape[self.axis]\n",
        "        if dim is None:\n",
        "            raise ValueError(\n",
        "                \"Axis \" + str(self.axis) + \" of \"\n",
        "                \"input tensor should have a defined dimension \"\n",
        "                \"but the layer received an input with shape \" + str(input_shape) + \".\"\n",
        "            )\n",
        "\n",
        "    def _set_number_of_groups_for_instance_norm(self, input_shape):\n",
        "        dim = input_shape[self.axis]\n",
        "\n",
        "        if self.groups == -1:\n",
        "            self.groups = dim\n",
        "\n",
        "    def _check_size_of_dimensions(self, input_shape):\n",
        "\n",
        "        dim = input_shape[self.axis]\n",
        "        if dim < self.groups:\n",
        "            raise ValueError(\n",
        "                \"Number of groups (\" + str(self.groups) + \") cannot be \"\n",
        "                \"more than the number of channels (\" + str(dim) + \").\"\n",
        "            )\n",
        "\n",
        "        if dim % self.groups != 0:\n",
        "            raise ValueError(\n",
        "                \"Number of groups (\" + str(self.groups) + \") must be a \"\n",
        "                \"multiple of the number of channels (\" + str(dim) + \").\"\n",
        "            )\n",
        "\n",
        "    def _check_axis(self):\n",
        "\n",
        "        if self.axis == 0:\n",
        "            raise ValueError(\n",
        "                \"You are trying to normalize your batch axis. Do you want to \"\n",
        "                \"use tf.layer.batch_normalization instead\"\n",
        "            )\n",
        "\n",
        "    def _create_input_spec(self, input_shape):\n",
        "\n",
        "        dim = input_shape[self.axis]\n",
        "        self.input_spec = tf.keras.layers.InputSpec(\n",
        "            ndim=len(input_shape), axes={self.axis: dim}\n",
        "        )\n",
        "\n",
        "    def _add_gamma_weight(self, input_shape):\n",
        "\n",
        "        dim = input_shape[self.axis]\n",
        "        shape = (dim,)\n",
        "\n",
        "        if self.scale:\n",
        "            self.gamma = self.add_weight(\n",
        "                shape=shape,\n",
        "                name=\"gamma\",\n",
        "                initializer=self.gamma_initializer,\n",
        "                regularizer=self.gamma_regularizer,\n",
        "                constraint=self.gamma_constraint,\n",
        "            )\n",
        "        else:\n",
        "            self.gamma = None\n",
        "\n",
        "    def _add_beta_weight(self, input_shape):\n",
        "\n",
        "        dim = input_shape[self.axis]\n",
        "        shape = (dim,)\n",
        "\n",
        "        if self.center:\n",
        "            self.beta = self.add_weight(\n",
        "                shape=shape,\n",
        "                name=\"beta\",\n",
        "                initializer=self.beta_initializer,\n",
        "                regularizer=self.beta_regularizer,\n",
        "                constraint=self.beta_constraint,\n",
        "            )\n",
        "        else:\n",
        "            self.beta = None\n",
        "\n",
        "    def _create_broadcast_shape(self, input_shape):\n",
        "        broadcast_shape = [1] * len(input_shape)\n",
        "        is_instance_norm = (input_shape[self.axis] // self.groups) == 1\n",
        "        if not is_instance_norm:\n",
        "            broadcast_shape[self.axis] = input_shape[self.axis] // self.groups\n",
        "            broadcast_shape.insert(self.axis, self.groups)\n",
        "        else:\n",
        "            broadcast_shape[self.axis] = self.groups\n",
        "        return broadcast_shape\n",
        "\n",
        "\n",
        "class StochasticDepth(tf.keras.layers.Layer):\n",
        "    \"\"\"Stochastic Depth layer.\n",
        "    Implements Stochastic Depth as described in\n",
        "    [Deep Networks with Stochastic Depth](https://arxiv.org/abs/1603.09382), to randomly drop residual branches\n",
        "    in residual architectures.\n",
        "    Usage:\n",
        "    Residual architectures with fixed depth, use residual branches that are merged back into the main network\n",
        "    by adding the residual branch back to the input:\n",
        "    >>> input = np.ones((1, 3, 3, 1), dtype = np.float32)\n",
        "    >>> residual = tf.keras.layers.Conv2D(1, 1)(input)\n",
        "    >>> output = tf.keras.layers.Add()([input, residual])\n",
        "    >>> output.shape\n",
        "    TensorShape([1, 3, 3, 1])\n",
        "    StochasticDepth acts as a drop-in replacement for the addition:\n",
        "    >>> input = np.ones((1, 3, 3, 1), dtype = np.float32)\n",
        "    >>> residual = tf.keras.layers.Conv2D(1, 1)(input)\n",
        "    >>> output = tfa.layers.StochasticDepth()([input, residual])\n",
        "    >>> output.shape\n",
        "    TensorShape([1, 3, 3, 1])\n",
        "    At train time, StochasticDepth returns:\n",
        "    $$\n",
        "    x[0] + b_l * x[1],\n",
        "    $$\n",
        "    where $b_l$ is a random Bernoulli variable with probability $P(b_l = 1) = p_l$\n",
        "    At test time, StochasticDepth rescales the activations of the residual branch based on the survival probability ($p_l$):\n",
        "    $$\n",
        "    x[0] + p_l * x[1]\n",
        "    $$\n",
        "    Args:\n",
        "        survival_probability: float, the probability of the residual branch being kept.\n",
        "    Call Args:\n",
        "        inputs:  List of `[shortcut, residual]` where `shortcut`, and `residual` are tensors of equal shape.\n",
        "    Output shape:\n",
        "        Equal to the shape of inputs `shortcut`, and `residual`\n",
        "    \"\"\"\n",
        "\n",
        "    @typechecked\n",
        "    def __init__(self, survival_probability: float = 0.5, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.survival_probability = survival_probability\n",
        "\n",
        "    def call(self, x, training=None):\n",
        "        if not isinstance(x, list) or len(x) != 2:\n",
        "            raise ValueError(\"input must be a list of length 2.\")\n",
        "\n",
        "        shortcut, residual = x\n",
        "\n",
        "        # Random bernoulli variable indicating whether the branch should be kept or not or not\n",
        "        b_l = tf.keras.backend.random_bernoulli([], p=self.survival_probability)\n",
        "\n",
        "        def _call_train():\n",
        "            return shortcut + b_l * residual\n",
        "\n",
        "        def _call_test():\n",
        "            # following line make this implementation differnet from `tensorflow_addons.StochasticDepth`\n",
        "            # we can't multiply `self.survival_probability` with `residual` during test time\n",
        "            # as it will disturb the fine-tuned weights if they are directly used with this architecture.\n",
        "            return shortcut + residual\n",
        "\n",
        "        return tf.keras.backend.in_train_phase(\n",
        "            _call_train, _call_test, training=training\n",
        "        )\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0]\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "\n",
        "        config = {\"survival_probability\": self.survival_probability}\n",
        "\n",
        "        return {**base_config, **config}"
      ],
      "metadata": {
        "id": "eUnQR2y-1cQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#                          encoder.py\n",
        "import tensorflow as tf\n",
        "\n",
        "class Conv1DWithWeightNorm(tf.keras.layers.Conv1D):\n",
        "    \"\"\"\n",
        "    Adapted from `tensorflow_addons.layers.WeightNormalization`\n",
        "    torch.nn.WeightNorm works slightly different. So, it's better to implement it\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        self._padding = kwargs.pop(\"padding\")\n",
        "        self.filter_axis = 0\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "    def _compute_kernel(self):\n",
        "        \"\"\"Generate weights with normalization.\"\"\"\n",
        "        self.kernel = (\n",
        "            tf.nn.l2_normalize(self.weight_v, axis=self.kernel_norm_axes)\n",
        "            * self.weight_g\n",
        "        )\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        super().build(input_shape)\n",
        "\n",
        "        kernel_norm_axes = list(range(self.kernel.shape.rank))\n",
        "        kernel_norm_axes.pop(self.filter_axis)\n",
        "        self.kernel_norm_axes = kernel_norm_axes\n",
        "\n",
        "        # renaming kernal variable for making similar to torch-weight-norm\n",
        "        self.kernel = tf.Variable(self.kernel, name=\"weight_v\", trainable=True)\n",
        "        self.weight_v = self.kernel\n",
        "\n",
        "        self._init_weight_g()\n",
        "\n",
        "    def _init_weight_g(self):\n",
        "        \"\"\"Set the norm of the weight vector.\"\"\"\n",
        "        self.weight_g = self.add_weight(\n",
        "            name=\"weight_g\",\n",
        "            shape=(int(self.weight_v.shape[self.filter_axis]), 1, 1),\n",
        "            initializer=\"ones\",\n",
        "            dtype=self.weight_v.dtype,\n",
        "            trainable=True,\n",
        "        )\n",
        "        kernel_norm = tf.sqrt(\n",
        "            tf.reduce_sum(tf.square(self.weight_v), axis=self.kernel_norm_axes)\n",
        "        )\n",
        "        self.weight_g.assign(kernel_norm[:, tf.newaxis, tf.newaxis])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        self._compute_kernel()\n",
        "        output = tf.pad(inputs, ((0, 0), (self._padding, self._padding), (0, 0)))\n",
        "        return super().call(output)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\"padding\": self._padding})\n",
        "        return config\n",
        "\n",
        "\n",
        "\n",
        "class StochasticDepth(tf.keras.layers.Layer):\n",
        "    \"\"\"Stochastic Depth layer.\n",
        "    Implements Stochastic Depth as described in\n",
        "    [Deep Networks with Stochastic Depth](https://arxiv.org/abs/1603.09382), to randomly drop residual branches\n",
        "    in residual architectures.\n",
        "    Usage:\n",
        "    Residual architectures with fixed depth, use residual branches that are merged back into the main network\n",
        "    by adding the residual branch back to the input:\n",
        "    >>> input = np.ones((1, 3, 3, 1), dtype = np.float32)\n",
        "    >>> residual = tf.keras.layers.Conv2D(1, 1)(input)\n",
        "    >>> output = tf.keras.layers.Add()([input, residual])\n",
        "    >>> output.shape\n",
        "    TensorShape([1, 3, 3, 1])\n",
        "    StochasticDepth acts as a drop-in replacement for the addition:\n",
        "    >>> input = np.ones((1, 3, 3, 1), dtype = np.float32)\n",
        "    >>> residual = tf.keras.layers.Conv2D(1, 1)(input)\n",
        "    >>> output = tfa.layers.StochasticDepth()([input, residual])\n",
        "    >>> output.shape\n",
        "    TensorShape([1, 3, 3, 1])\n",
        "    At train time, StochasticDepth returns:\n",
        "    $$\n",
        "    x[0] + b_l * x[1],\n",
        "    $$\n",
        "    where $b_l$ is a random Bernoulli variable with probability $P(b_l = 1) = p_l$\n",
        "    At test time, StochasticDepth rescales the activations of the residual branch based on the survival probability ($p_l$):\n",
        "    $$\n",
        "    x[0] + p_l * x[1]\n",
        "    $$\n",
        "    Args:\n",
        "        survival_probability: float, the probability of the residual branch being kept.\n",
        "    Call Args:\n",
        "        inputs:  List of `[shortcut, residual]` where `shortcut`, and `residual` are tensors of equal shape.\n",
        "    Output shape:\n",
        "        Equal to the shape of inputs `shortcut`, and `residual`\n",
        "    \"\"\"\n",
        "\n",
        "    @typechecked\n",
        "    def __init__(self, survival_probability: float = 0.5, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.survival_probability = survival_probability\n",
        "\n",
        "    def call(self, x, training=None):\n",
        "        if not isinstance(x, list) or len(x) != 2:\n",
        "            raise ValueError(\"input must be a list of length 2.\")\n",
        "\n",
        "        shortcut, residual = x\n",
        "\n",
        "        # Random bernoulli variable indicating whether the branch should be kept or not or not\n",
        "        b_l = tf.keras.backend.random_bernoulli([], p=self.survival_probability)\n",
        "\n",
        "        def _call_train():\n",
        "            return shortcut + b_l * residual\n",
        "\n",
        "        def _call_test():\n",
        "            # following line make this implementation differnet from `tensorflow_addons.StochasticDepth`\n",
        "            # we can't multiply `self.survival_probability` with `residual` during test time\n",
        "            # as it will disturb the fine-tuned weights if they are directly used with this architecture.\n",
        "            return shortcut + residual\n",
        "\n",
        "        return tf.keras.backend.in_train_phase(\n",
        "            _call_train, _call_test, training=training\n",
        "        )\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0]\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "\n",
        "        config = {\"survival_probability\": self.survival_probability}\n",
        "\n",
        "        return {**base_config, **config}\n",
        "\n",
        "class TransformerAttention(tf.keras.layers.Layer):\n",
        "    \"\"\"Attention layer from `Attention Is All You Need`\"\"\"\n",
        "\n",
        "    def __init__(self, hidden_size, num_heads, dropout=0.1, name=\"attention\"):\n",
        "        super().__init__(name=name)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_heads = num_heads\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.q = tf.keras.layers.Dense(hidden_size, name=\"q_proj\")\n",
        "        self.k = tf.keras.layers.Dense(hidden_size, name=\"k_proj\")\n",
        "        self.v = tf.keras.layers.Dense(hidden_size, name=\"v_proj\")\n",
        "        self.projection = tf.keras.layers.Dense(hidden_size, name=\"out_proj\")\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
        "\n",
        "    def call(self, batch, attention_mask=None, training=False):\n",
        "        head_size = batch.shape[2] // self.num_heads\n",
        "        q_out = self._prepare_either_qkv(self.q(batch), head_size)\n",
        "        k_out = self._prepare_either_qkv(self.k(batch), head_size)\n",
        "        v_out = self._prepare_either_qkv(self.v(batch), head_size)\n",
        "\n",
        "        q_out = q_out * head_size ** (-0.5)\n",
        "\n",
        "        batch = self.get_context(q_out, k_out, v_out, attention_mask=attention_mask, training=training)\n",
        "        batch = self.projection(batch)\n",
        "        return batch\n",
        "\n",
        "    def get_context(self, q_out, k_out, v_out, attention_mask=None, training=False):\n",
        "\n",
        "        b, h, l, d = q_out.shape\n",
        "        attn_scores = tf.matmul(q_out, k_out, transpose_b=True)  # \"bhqd,bhkd->bhqk\"\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            attn_scores = attn_scores + attention_mask\n",
        "\n",
        "        attn_scores = self.dropout(\n",
        "            tf.nn.softmax(attn_scores, axis=-1), training=training\n",
        "        )\n",
        "        context = tf.matmul(attn_scores, v_out)  # \"bhll,bhld->bhld\"\n",
        "        context = tf.transpose(context, perm=(0, 2, 1, 3))\n",
        "        return tf.reshape(context, (-1, l, h * d))\n",
        "\n",
        "    def _prepare_either_qkv(self, tensor, head_size):\n",
        "        bsz, seqlen, _ = tensor.shape\n",
        "        tensor = tf.reshape(tensor, (-1, seqlen, self.num_heads, head_size))\n",
        "        return tf.transpose(\n",
        "            tensor, perm=(0, 2, 1, 3)\n",
        "        )  # -> bsz, num_heads, seqlen, head_size\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"hidden_size\": self.hidden_size,\n",
        "                \"num_heads\": self.num_heads,\n",
        "                \"dropout\": self.dropout,\n",
        "            }\n",
        "        )\n",
        "        return config\n",
        "\n",
        "\n",
        "class TransformerLayer(tf.keras.layers.Layer):\n",
        "    def __init__(\n",
        "        self,\n",
        "        hidden_size,\n",
        "        num_heads,\n",
        "        intermediate_size,\n",
        "        survival_prob=0.9,\n",
        "        layer_norm_eps=1e-5,\n",
        "        is_gelu_approx=False,\n",
        "        dropout=0.1,\n",
        "        attention_norm_type=\"postnorm\",\n",
        "        name=None,\n",
        "    ):\n",
        "        super().__init__(name=name)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_heads = num_heads\n",
        "        self.intermediate_size = intermediate_size\n",
        "        self.survival_prob = survival_prob\n",
        "        self.layer_norm_eps = layer_norm_eps\n",
        "        self.is_gelu_approx = is_gelu_approx\n",
        "        self.dropout = dropout\n",
        "        self.attention_norm_type = attention_norm_type\n",
        "\n",
        "        self.attention = TransformerAttention(\n",
        "            hidden_size, num_heads, dropout=dropout, name=\"attention\"\n",
        "        )\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
        "\n",
        "        self.layer_norm = tf.keras.layers.LayerNormalization(\n",
        "            epsilon=layer_norm_eps, name=\"layer_norm\"\n",
        "        )\n",
        "        self.intermediate = tf.keras.layers.Dense(\n",
        "            intermediate_size, name=\"feed_forward/intermediate_dense\"\n",
        "        )\n",
        "        self.attn_output = tf.keras.layers.Dense(\n",
        "            hidden_size, name=\"feed_forward/output_dense\"\n",
        "        )\n",
        "        self.final_layer_norm = tf.keras.layers.LayerNormalization(\n",
        "            epsilon=layer_norm_eps,\n",
        "            name=\"final_layer_norm\",\n",
        "        )\n",
        "        self.stochastic_depth = StochasticDepth(survival_prob)\n",
        "\n",
        "    def call(self, batch, attention_mask=None, training=False):\n",
        "\n",
        "        # self_attn\n",
        "        residual = batch\n",
        "        if self.attention_norm_type == \"prenorm\":\n",
        "            batch = self.layer_norm(batch)\n",
        "        batch = self.attention(batch, attention_mask=attention_mask, training=training)\n",
        "        batch = self.dropout(batch, training=training)\n",
        "        batch = batch + residual\n",
        "        if self.attention_norm_type == \"postnorm\":\n",
        "            batch = self.layer_norm(batch)\n",
        "\n",
        "        # ffn\n",
        "        residual = batch\n",
        "        if self.attention_norm_type == \"prenorm\":\n",
        "            batch = self.final_layer_norm(batch)\n",
        "        batch = tf.nn.gelu(self.intermediate(batch), approximate=self.is_gelu_approx)\n",
        "        batch = self.attn_output(self.dropout(batch, training=training))\n",
        "        # stochastic depth from `paper <https://arxiv.org/abs/1603.09382> __`\n",
        "        batch = self.stochastic_depth([residual, batch], training=training)\n",
        "        if self.attention_norm_type == \"postnorm\":\n",
        "            batch = self.final_layer_norm(batch)\n",
        "\n",
        "        return batch\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"hidden_size\": self.hidden_size,\n",
        "                \"num_heads\": self.num_heads,\n",
        "                \"intermediate_size\": self.intermediate_size,\n",
        "                \"survival_prob\": self.survival_prob,\n",
        "                \"layer_norm_eps\": self.layer_norm_eps,\n",
        "                \"is_gelu_approx\": self.is_gelu_approx,\n",
        "                \"dropout\": self.dropout,\n",
        "                \"attention_norm_type\": self.attention_norm_type,\n",
        "            }\n",
        "        )\n",
        "        return config\n",
        "\n",
        "\n",
        "class PositionalConvEmbedding(tf.keras.layers.Layer):\n",
        "    def __init__(\n",
        "        self,\n",
        "        hidden_size,\n",
        "        num_conv_pos_embeddings,\n",
        "        num_conv_pos_embedding_groups,\n",
        "        is_gelu_approx=False,\n",
        "        name=\"pos_conv_embed\",\n",
        "    ):\n",
        "        super().__init__(name=name)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_conv_pos_embeddings = num_conv_pos_embeddings\n",
        "        self.num_conv_pos_embedding_groups = num_conv_pos_embedding_groups\n",
        "        self.is_gelu_approx = is_gelu_approx\n",
        "\n",
        "        self.conv = Conv1DWithWeightNorm(\n",
        "            hidden_size,\n",
        "            num_conv_pos_embeddings,\n",
        "            padding=num_conv_pos_embeddings // 2,\n",
        "            groups=num_conv_pos_embedding_groups,\n",
        "            name=\"conv\",\n",
        "        )\n",
        "        self.is_padding_wrong = num_conv_pos_embeddings % 2 == 0\n",
        "\n",
        "    def call(self, batch):\n",
        "        batch = self.conv(batch)\n",
        "        if self.is_padding_wrong:\n",
        "            batch = batch[:, :-1, :]\n",
        "        return tf.nn.gelu(batch, approximate=self.is_gelu_approx)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"hidden_size\": self.hidden_size,\n",
        "                \"num_conv_pos_embeddings\": self.num_conv_pos_embeddings,\n",
        "                \"num_conv_pos_embedding_groups\": self.num_conv_pos_embedding_groups,\n",
        "                \"is_gelu_approx\": self.is_gelu_approx,\n",
        "            }\n",
        "        )\n",
        "        return config\n",
        "\n",
        "\n",
        "class Wav2Vec2Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(\n",
        "        self,\n",
        "        hidden_size,\n",
        "        num_heads,\n",
        "        num_layers,\n",
        "        intermediate_size,\n",
        "        num_conv_pos_embeddings,\n",
        "        num_conv_pos_embedding_groups,\n",
        "        survival_prob=0.9,\n",
        "        dropout=0.1,\n",
        "        layer_norm_eps=1e-5,\n",
        "        is_gelu_approx=False,\n",
        "        attention_norm_type=\"postnorm\",\n",
        "        name=\"encoder\",\n",
        "    ):\n",
        "        super().__init__(name=name)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_heads = num_heads\n",
        "        self.num_layers = num_layers\n",
        "        self.intermediate_size = intermediate_size\n",
        "        self.num_conv_pos_embeddings = num_conv_pos_embeddings\n",
        "        self.num_conv_pos_embedding_groups = num_conv_pos_embedding_groups\n",
        "        self.survival_prob = survival_prob\n",
        "        self.dropout = dropout\n",
        "        self.layer_norm_eps = layer_norm_eps\n",
        "        self.is_gelu_approx = is_gelu_approx\n",
        "        self.attention_norm_type = attention_norm_type\n",
        "\n",
        "        self.pos_conv_embed = PositionalConvEmbedding(\n",
        "            hidden_size,\n",
        "            num_conv_pos_embeddings,\n",
        "            num_conv_pos_embedding_groups,\n",
        "            is_gelu_approx=is_gelu_approx,\n",
        "            name=\"pos_conv_embed\",\n",
        "        )\n",
        "        self.layer_norm = tf.keras.layers.LayerNormalization(\n",
        "            epsilon=layer_norm_eps, name=\"layer_norm\"\n",
        "        )\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
        "        self.layers = [\n",
        "            TransformerLayer(\n",
        "                hidden_size,\n",
        "                num_heads,\n",
        "                intermediate_size,\n",
        "                survival_prob=survival_prob,\n",
        "                layer_norm_eps=layer_norm_eps,\n",
        "                is_gelu_approx=is_gelu_approx,\n",
        "                dropout=dropout,\n",
        "                attention_norm_type=attention_norm_type,\n",
        "                name=f\"layers/{i}\",\n",
        "            )\n",
        "            for i in range(num_layers)\n",
        "        ]\n",
        "\n",
        "    def call(self, batch, attention_mask=None, training=False):\n",
        "        if attention_mask is not None:\n",
        "            batch = tf.where(attention_mask[:, :, tf.newaxis], batch, 0.0)\n",
        "            seqlen = batch.shape[1]\n",
        "\n",
        "            attention_mask = tf.cast(attention_mask, dtype=batch.dtype)\n",
        "            attention_mask = (1.0 - attention_mask) * tf.constant(-10000.0)\n",
        "\n",
        "            # tf.broadcast_to doesn't work when batch size is unknown (especially with TFSavedModel)\n",
        "            attention_mask = attention_mask[tf.newaxis, :, tf.newaxis, :]\n",
        "            attention_mask = tf.repeat(attention_mask, seqlen, axis=0)\n",
        "            attention_mask = tf.reshape(attention_mask, (seqlen, -1, 1, seqlen))\n",
        "            attention_mask = tf.transpose(attention_mask, perm=[1, 2, 0, 3])\n",
        "\n",
        "        batch = batch + self.pos_conv_embed(batch)\n",
        "\n",
        "        if self.attention_norm_type == \"postnorm\":\n",
        "            batch = self.layer_norm(batch)\n",
        "\n",
        "        batch = self.dropout(batch, training=training)\n",
        "        for layer in self.layers:\n",
        "            batch = layer(batch, attention_mask=attention_mask, training=training)\n",
        "\n",
        "        if self.attention_norm_type == \"prenorm\":\n",
        "            batch = self.layer_norm(batch)\n",
        "        return batch\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"hidden_size\": self.hidden_size,\n",
        "                \"num_heads\": self.num_heads,\n",
        "                \"num_layers\": self.num_layers,\n",
        "                \"intermediate_size\": self.intermediate_size,\n",
        "                \"num_conv_pos_embeddings\": self.num_conv_pos_embeddings,\n",
        "                \"num_conv_pos_embedding_groups\": self.num_conv_pos_embedding_groups,\n",
        "                \"survival_prob\": self.survival_prob,\n",
        "                \"dropout\": self.dropout,\n",
        "                \"layer_norm_eps\": self.layer_norm_eps,\n",
        "                \"is_gelu_approx\": self.is_gelu_approx,\n",
        "                \"attention_norm_type\": self.attention_norm_type,\n",
        "            }\n",
        "        )\n",
        "        return config"
      ],
      "metadata": {
        "id": "LdYqgPNs3Ue7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#                             feature_extractor.py\n",
        "import tensorflow as tf\n",
        "\n",
        "class GroupNormalization(tf.keras.layers.Layer):\n",
        "    \"\"\"Group normalization layer.\n",
        "    Source: \"Group Normalization\" (Yuxin Wu & Kaiming He, 2018)\n",
        "    https://arxiv.org/abs/1803.08494\n",
        "    Group Normalization divides the channels into groups and computes\n",
        "    within each group the mean and variance for normalization.\n",
        "    Empirically, its accuracy is more stable than batch norm in a wide\n",
        "    range of small batch sizes, if learning rate is adjusted linearly\n",
        "    with batch sizes.\n",
        "    Relation to Layer Normalization:\n",
        "    If the number of groups is set to 1, then this operation becomes identical\n",
        "    to Layer Normalization.\n",
        "    Relation to Instance Normalization:\n",
        "    If the number of groups is set to the\n",
        "    input dimension (number of groups is equal\n",
        "    to number of channels), then this operation becomes\n",
        "    identical to Instance Normalization.\n",
        "    Args:\n",
        "        groups: Integer, the number of groups for Group Normalization.\n",
        "            Can be in the range [1, N] where N is the input dimension.\n",
        "            The input dimension must be divisible by the number of groups.\n",
        "            Defaults to 32.\n",
        "        axis: Integer, the axis that should be normalized.\n",
        "        epsilon: Small float added to variance to avoid dividing by zero.\n",
        "        center: If True, add offset of `beta` to normalized tensor.\n",
        "            If False, `beta` is ignored.\n",
        "        scale: If True, multiply by `gamma`.\n",
        "            If False, `gamma` is not used.\n",
        "        beta_initializer: Initializer for the beta weight.\n",
        "        gamma_initializer: Initializer for the gamma weight.\n",
        "        beta_regularizer: Optional regularizer for the beta weight.\n",
        "        gamma_regularizer: Optional regularizer for the gamma weight.\n",
        "        beta_constraint: Optional constraint for the beta weight.\n",
        "        gamma_constraint: Optional constraint for the gamma weight.\n",
        "    Input shape:\n",
        "        Arbitrary. Use the keyword argument `input_shape`\n",
        "        (tuple of integers, does not include the samples axis)\n",
        "        when using this layer as the first layer in a model.\n",
        "    Output shape:\n",
        "        Same shape as input.\n",
        "    \"\"\"\n",
        "\n",
        "    @typechecked\n",
        "    def __init__(\n",
        "        self,\n",
        "        groups: int = 32,\n",
        "        axis: int = -1,\n",
        "        epsilon: float = 1e-3,\n",
        "        center: bool = True,\n",
        "        scale: bool = True,\n",
        "        beta_initializer=\"zeros\",\n",
        "        gamma_initializer=\"ones\",\n",
        "        beta_regularizer=None,\n",
        "        gamma_regularizer=None,\n",
        "        beta_constraint=None,\n",
        "        gamma_constraint=None,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super().__init__(**kwargs)\n",
        "        self.supports_masking = True\n",
        "        self.groups = groups\n",
        "        self.axis = axis\n",
        "        self.epsilon = epsilon\n",
        "        self.center = center\n",
        "        self.scale = scale\n",
        "        self.beta_initializer = tf.keras.initializers.get(beta_initializer)\n",
        "        self.gamma_initializer = tf.keras.initializers.get(gamma_initializer)\n",
        "        self.beta_regularizer = tf.keras.regularizers.get(beta_regularizer)\n",
        "        self.gamma_regularizer = tf.keras.regularizers.get(gamma_regularizer)\n",
        "        self.beta_constraint = tf.keras.constraints.get(beta_constraint)\n",
        "        self.gamma_constraint = tf.keras.constraints.get(gamma_constraint)\n",
        "        self._check_axis()\n",
        "\n",
        "    def build(self, input_shape):\n",
        "\n",
        "        self._check_if_input_shape_is_none(input_shape)\n",
        "        self._set_number_of_groups_for_instance_norm(input_shape)\n",
        "        self._check_size_of_dimensions(input_shape)\n",
        "        self._create_input_spec(input_shape)\n",
        "\n",
        "        self._add_gamma_weight(input_shape)\n",
        "        self._add_beta_weight(input_shape)\n",
        "        self.built = True\n",
        "        super().build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "\n",
        "        input_shape = tf.keras.backend.int_shape(inputs)\n",
        "        tensor_input_shape = tf.shape(inputs)\n",
        "\n",
        "        reshaped_inputs, group_shape = self._reshape_into_groups(\n",
        "            inputs, input_shape, tensor_input_shape\n",
        "        )\n",
        "\n",
        "        normalized_inputs = self._apply_normalization(reshaped_inputs, input_shape)\n",
        "\n",
        "        is_instance_norm = (input_shape[self.axis] // self.groups) == 1\n",
        "        if not is_instance_norm:\n",
        "            outputs = tf.reshape(normalized_inputs, tensor_input_shape)\n",
        "        else:\n",
        "            outputs = normalized_inputs\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            \"groups\": self.groups,\n",
        "            \"axis\": self.axis,\n",
        "            \"epsilon\": self.epsilon,\n",
        "            \"center\": self.center,\n",
        "            \"scale\": self.scale,\n",
        "            \"beta_initializer\": tf.keras.initializers.serialize(self.beta_initializer),\n",
        "            \"gamma_initializer\": tf.keras.initializers.serialize(\n",
        "                self.gamma_initializer\n",
        "            ),\n",
        "            \"beta_regularizer\": tf.keras.regularizers.serialize(self.beta_regularizer),\n",
        "            \"gamma_regularizer\": tf.keras.regularizers.serialize(\n",
        "                self.gamma_regularizer\n",
        "            ),\n",
        "            \"beta_constraint\": tf.keras.constraints.serialize(self.beta_constraint),\n",
        "            \"gamma_constraint\": tf.keras.constraints.serialize(self.gamma_constraint),\n",
        "        }\n",
        "        base_config = super().get_config()\n",
        "        return {**base_config, **config}\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape\n",
        "\n",
        "    def _reshape_into_groups(self, inputs, input_shape, tensor_input_shape):\n",
        "\n",
        "        group_shape = [tensor_input_shape[i] for i in range(len(input_shape))]\n",
        "        is_instance_norm = (input_shape[self.axis] // self.groups) == 1\n",
        "        if not is_instance_norm:\n",
        "            group_shape[self.axis] = input_shape[self.axis] // self.groups\n",
        "            group_shape.insert(self.axis, self.groups)\n",
        "            group_shape = tf.stack(group_shape)\n",
        "            reshaped_inputs = tf.reshape(inputs, group_shape)\n",
        "            return reshaped_inputs, group_shape\n",
        "        else:\n",
        "            return inputs, group_shape\n",
        "\n",
        "    def _apply_normalization(self, reshaped_inputs, input_shape):\n",
        "\n",
        "        group_shape = tf.keras.backend.int_shape(reshaped_inputs)\n",
        "        group_reduction_axes = list(range(1, len(group_shape)))\n",
        "        is_instance_norm = (input_shape[self.axis] // self.groups) == 1\n",
        "        if not is_instance_norm:\n",
        "            axis = -2 if self.axis == -1 else self.axis - 1\n",
        "        else:\n",
        "            axis = -1 if self.axis == -1 else self.axis - 1\n",
        "        group_reduction_axes.pop(axis)\n",
        "\n",
        "        mean, variance = tf.nn.moments(\n",
        "            reshaped_inputs, group_reduction_axes, keepdims=True\n",
        "        )\n",
        "\n",
        "        gamma, beta = self._get_reshaped_weights(input_shape)\n",
        "        normalized_inputs = tf.nn.batch_normalization(\n",
        "            reshaped_inputs,\n",
        "            mean=mean,\n",
        "            variance=variance,\n",
        "            scale=gamma,\n",
        "            offset=beta,\n",
        "            variance_epsilon=self.epsilon,\n",
        "        )\n",
        "        return normalized_inputs\n",
        "\n",
        "    def _get_reshaped_weights(self, input_shape):\n",
        "        broadcast_shape = self._create_broadcast_shape(input_shape)\n",
        "        gamma = None\n",
        "        beta = None\n",
        "        if self.scale:\n",
        "            gamma = tf.reshape(self.gamma, broadcast_shape)\n",
        "\n",
        "        if self.center:\n",
        "            beta = tf.reshape(self.beta, broadcast_shape)\n",
        "        return gamma, beta\n",
        "\n",
        "    def _check_if_input_shape_is_none(self, input_shape):\n",
        "        dim = input_shape[self.axis]\n",
        "        if dim is None:\n",
        "            raise ValueError(\n",
        "                \"Axis \" + str(self.axis) + \" of \"\n",
        "                \"input tensor should have a defined dimension \"\n",
        "                \"but the layer received an input with shape \" + str(input_shape) + \".\"\n",
        "            )\n",
        "\n",
        "    def _set_number_of_groups_for_instance_norm(self, input_shape):\n",
        "        dim = input_shape[self.axis]\n",
        "\n",
        "        if self.groups == -1:\n",
        "            self.groups = dim\n",
        "\n",
        "    def _check_size_of_dimensions(self, input_shape):\n",
        "\n",
        "        dim = input_shape[self.axis]\n",
        "        if dim < self.groups:\n",
        "            raise ValueError(\n",
        "                \"Number of groups (\" + str(self.groups) + \") cannot be \"\n",
        "                \"more than the number of channels (\" + str(dim) + \").\"\n",
        "            )\n",
        "\n",
        "        if dim % self.groups != 0:\n",
        "            raise ValueError(\n",
        "                \"Number of groups (\" + str(self.groups) + \") must be a \"\n",
        "                \"multiple of the number of channels (\" + str(dim) + \").\"\n",
        "            )\n",
        "\n",
        "    def _check_axis(self):\n",
        "\n",
        "        if self.axis == 0:\n",
        "            raise ValueError(\n",
        "                \"You are trying to normalize your batch axis. Do you want to \"\n",
        "                \"use tf.layer.batch_normalization instead\"\n",
        "            )\n",
        "\n",
        "    def _create_input_spec(self, input_shape):\n",
        "\n",
        "        dim = input_shape[self.axis]\n",
        "        self.input_spec = tf.keras.layers.InputSpec(\n",
        "            ndim=len(input_shape), axes={self.axis: dim}\n",
        "        )\n",
        "\n",
        "    def _add_gamma_weight(self, input_shape):\n",
        "\n",
        "        dim = input_shape[self.axis]\n",
        "        shape = (dim,)\n",
        "\n",
        "        if self.scale:\n",
        "            self.gamma = self.add_weight(\n",
        "                shape=shape,\n",
        "                name=\"gamma\",\n",
        "                initializer=self.gamma_initializer,\n",
        "                regularizer=self.gamma_regularizer,\n",
        "                constraint=self.gamma_constraint,\n",
        "            )\n",
        "        else:\n",
        "            self.gamma = None\n",
        "\n",
        "    def _add_beta_weight(self, input_shape):\n",
        "\n",
        "        dim = input_shape[self.axis]\n",
        "        shape = (dim,)\n",
        "\n",
        "        if self.center:\n",
        "            self.beta = self.add_weight(\n",
        "                shape=shape,\n",
        "                name=\"beta\",\n",
        "                initializer=self.beta_initializer,\n",
        "                regularizer=self.beta_regularizer,\n",
        "                constraint=self.beta_constraint,\n",
        "            )\n",
        "        else:\n",
        "            self.beta = None\n",
        "\n",
        "    def _create_broadcast_shape(self, input_shape):\n",
        "        broadcast_shape = [1] * len(input_shape)\n",
        "        is_instance_norm = (input_shape[self.axis] // self.groups) == 1\n",
        "        if not is_instance_norm:\n",
        "            broadcast_shape[self.axis] = input_shape[self.axis] // self.groups\n",
        "            broadcast_shape.insert(self.axis, self.groups)\n",
        "        else:\n",
        "            broadcast_shape[self.axis] = self.groups\n",
        "        return broadcast_shape\n",
        "\n",
        "class FeatureExtractorLayer(tf.keras.layers.Layer):\n",
        "    def __init__(\n",
        "        self,\n",
        "        filter_sizes,\n",
        "        kernal_sizes,\n",
        "        strides,\n",
        "        conv_bias=False,\n",
        "        is_gelu_approx=False,\n",
        "        layer_id=0,\n",
        "        feature_extractor_norm_type=\"group\",\n",
        "        name=None,\n",
        "    ):\n",
        "        super().__init__(name=name)\n",
        "        self.filter_sizes = filter_sizes\n",
        "        self.kernal_sizes = kernal_sizes\n",
        "        self.strides = strides\n",
        "        self.conv_bias = conv_bias\n",
        "        self.is_gelu_approx = is_gelu_approx\n",
        "        self.layer_id = layer_id\n",
        "        self.feature_extractor_norm_type = feature_extractor_norm_type\n",
        "\n",
        "        conv_dim = filter_sizes[layer_id]\n",
        "        kernal_size = kernal_sizes[layer_id]\n",
        "        stride = strides[layer_id]\n",
        "\n",
        "        self.conv_layer = tf.keras.layers.Conv1D(\n",
        "            conv_dim,\n",
        "            kernal_size,\n",
        "            strides=stride,\n",
        "            use_bias=conv_bias,\n",
        "            name=\"conv\",\n",
        "        )\n",
        "\n",
        "        self.layer_norm = None\n",
        "        if self.feature_extractor_norm_type == \"group\":\n",
        "            if layer_id == 0:\n",
        "                self.layer_norm = GroupNormalization(\n",
        "                    conv_dim,\n",
        "                    axis=-1,\n",
        "                    name=\"layer_norm\",\n",
        "                    epsilon=1e-5,\n",
        "                )\n",
        "        elif self.feature_extractor_norm_type == \"layer\":\n",
        "            # TODO: check value of axis\n",
        "            self.layer_norm = tf.keras.layers.LayerNormalization(axis=-1, epsilon=1e-5, name=\"layer_norm\")\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "    def call(self, batch):\n",
        "        batch = self.conv_layer(batch)\n",
        "        if self.layer_norm is not None:\n",
        "            batch = self.layer_norm(batch)\n",
        "        batch = tf.nn.gelu(batch, approximate=self.is_gelu_approx)\n",
        "        return batch\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"filter_sizes\": self.filter_sizes,\n",
        "                \"kernal_sizes\": self.kernal_sizes,\n",
        "                \"strides\": self.strides,\n",
        "                \"conv_bias\": self.conv_bias,\n",
        "                \"is_gelu_approx\": self.is_gelu_approx,\n",
        "                \"layer_id\": self.layer_id,\n",
        "                \"feature_extractor_norm_type\": self.feature_extractor_norm_type,\n",
        "            }\n",
        "        )\n",
        "        return config\n",
        "\n",
        "\n",
        "class FeatureProjection(tf.keras.layers.Layer):\n",
        "    def __init__(\n",
        "        self, hidden_size, layer_norm_eps=1e-5, dropout=0.1, name=\"feature_projection\"\n",
        "    ):\n",
        "        super().__init__(name=name)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.layer_norm_eps = layer_norm_eps\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.layer_norm = tf.keras.layers.LayerNormalization(\n",
        "            epsilon=layer_norm_eps, name=\"layer_norm\"\n",
        "        )\n",
        "        self.projection = tf.keras.layers.Dense(hidden_size, name=\"projection\")\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
        "\n",
        "    def call(self, batch, training=False):\n",
        "        batch = self.layer_norm(batch)\n",
        "        batch = self.projection(batch)\n",
        "        return self.dropout(batch, training=training)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"hidden_size\": self.hidden_size,\n",
        "                \"layer_norm_eps\": self.layer_norm_eps,\n",
        "                \"dropout\": self.dropout,\n",
        "            }\n",
        "        )\n",
        "        return config"
      ],
      "metadata": {
        "id": "rXP5evZ4BYyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#             losses.py\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "class CTCLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self, config, model_input_shape, division_factor=1):\n",
        "        super().__init__(reduction=tf.keras.losses.Reduction.SUM)\n",
        "        self.kernal_sizes = config.kernal_sizes\n",
        "        self.strides = config.strides\n",
        "        self.pad_id = config.pad_id\n",
        "        self.division_factor = division_factor\n",
        "\n",
        "        self.model_input_shape = model_input_shape\n",
        "\n",
        "    def call(self, labels, hidden_states):\n",
        "        \"\"\"\n",
        "        This methods wraps up `tf.nn.ctc_loss` and returns the ctc-loss for batch.\n",
        "        Args:\n",
        "            labels (:obj: `tf.Tensor`):\n",
        "                This is batch of tokenized text labels.\n",
        "            hidden_states (:obj: `tf.Tensor`):\n",
        "                This is the output of LM head of `Wav2Vec2ForCTC.call(...)`.\n",
        "        Returns:\n",
        "            loss (:obj: `tf.Tensor`):\n",
        "                This is the summation/mean of CTC loss of the batch. Mean/Summation will be decided by\n",
        "                `loss_reduction` parameter in your config.\n",
        "        \"\"\"\n",
        "        input_length = tf.ones(self.model_input_shape[0]) * self.model_input_shape[1]\n",
        "        logit_length = self._get_logit_length(input_length)\n",
        "\n",
        "        label_mask = tf.cast(labels != self.pad_id, tf.int32)\n",
        "        label_length = tf.reduce_sum(label_mask, axis=-1)\n",
        "\n",
        "        loss = tf.nn.ctc_loss(\n",
        "            labels=labels,\n",
        "            logits=hidden_states,\n",
        "            label_length=label_length,\n",
        "            logit_length=logit_length,\n",
        "            logits_time_major=False,\n",
        "            blank_index=self.pad_id,\n",
        "            name=\"ctc-loss\",\n",
        "        )\n",
        "\n",
        "        return loss / self.division_factor\n",
        "\n",
        "    def _get_logit_length(self, input_length):\n",
        "        \"\"\"\n",
        "        This will return length of the sequence at the end of convolutional layers\n",
        "        i.e. seqlen fed to transformer encoder.\n",
        "        \"\"\"\n",
        "        kernal_sizes = self.kernal_sizes\n",
        "        strides = self.strides\n",
        "        for kernal_size, stride in zip(kernal_sizes, strides):\n",
        "            input_length = 1 + (input_length - kernal_size) // stride\n",
        "        return input_length"
      ],
      "metadata": {
        "id": "rrrLq7Hon8MD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install huggingface_hub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3f4czHmwnn-",
        "outputId": "5338b120-0fde-4921-b46b-be58442f1100"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting huggingface_hub\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████                           | 10 kB 21.5 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 20 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 30 kB 18.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 40 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 51 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 61 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 67 kB 3.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (3.6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (4.62.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (3.10.0.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (4.11.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (2.23.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (3.13)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->huggingface_hub) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface_hub) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface_hub) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface_hub) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface_hub) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface_hub) (1.24.3)\n",
            "Installing collected packages: huggingface-hub\n",
            "Successfully installed huggingface-hub-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#                   modeling.py\n",
        "import os\n",
        "import logging\n",
        "import subprocess\n",
        "from dataclasses import replace\n",
        "from typing  import Optional\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from huggingface_hub import ModelHubMixin\n",
        "\n",
        "# from .config import Wave2Vec2Config\n",
        "\n",
        "class Wav2Vec2Config:\n",
        "  vocab_size: int = 32\n",
        "  dropout: int = 0.1\n",
        "  hidden_size: int = 768\n",
        "  num_heads: int = 12\n",
        "  num_layers: int = 12\n",
        "  intermediate_size: int = 3072\n",
        "  is_gelu_approx: bool = False\n",
        "  layer_norm_eps: float = 1e-5\n",
        "  survival_prob: float = 1.0\n",
        "  pad_id: int = 0\n",
        "\n",
        "\n",
        "  # positional embedding\n",
        "  num_conv_pos_embeddings: int = 128\n",
        "  num_conv_pos_embedding_groups: int = 16\n",
        "\n",
        "  # feature extractor\n",
        "  filter_sizes: list = field(\n",
        "      default_factory=lambda: [512, 512, 512, 512, 512, 512, 512]\n",
        "  )\n",
        "  kernal_sizes: list = field(default_factory=lambda: [10, 3, 3, 3, 3, 2, 2])\n",
        "  strides: list = field(default_factory=lambda: [5, 2, 2, 2, 2, 2, 2])\n",
        "  conv_bias: bool = False\n",
        "\n",
        "  # spec augmentation arguments\n",
        "  apply_spec_augment: bool = True\n",
        "  mask_time_prob: float = 0.05\n",
        "  mask_time_length: int = 10\n",
        "\n",
        "  attention_norm_type: str = \"postnorm\"\n",
        "  feature_extractor_norm_type: bool = \"group\"\n",
        "  is_robust: bool = False\n",
        "\n",
        "  def __post_init__(self):\n",
        "      if not (len(self.filter_sizes) == len(self.kernal_sizes) == len(self.strides)):\n",
        "          raise ValueError(\n",
        "              \"Length of filter_sizes, kernal_sizes, strides must match.\"\n",
        "          )\n",
        "      if self.hidden_size % self.num_heads != 0:\n",
        "          raise ValueError(\"Hidden size must be perfect multiple of num_heads.\")\n",
        "\n",
        "      assert self.feature_extractor_norm_type in [\"group\", \"layer\"], \"Only `group` / `layer` are supported\"\n",
        "      assert self.attention_norm_type in [\"prenorm\", \"postnorm\"], \"Only `prenorm` / `postnorm` are supported\"\n",
        "\n",
        "  def save_pretrained(self, save_dir):\n",
        "      os.makedirs(save_dir, exist_ok=True)\n",
        "      with open(os.path.join(save_dir, \"config.json\"), \"w\") as f:\n",
        "          json.dump(asdict(self), f)\n",
        "\n",
        "# from .encoder import Wav2Vec2Encoder\n",
        "\n",
        "class Wav2Vec2Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(\n",
        "        self,\n",
        "        hidden_size,\n",
        "        num_heads,\n",
        "        num_layers,\n",
        "        intermediate_size,\n",
        "        num_conv_pos_embeddings,\n",
        "        num_conv_pos_embedding_groups,\n",
        "        survival_prob=0.9,\n",
        "        dropout=0.1,\n",
        "        layer_norm_eps=1e-5,\n",
        "        is_gelu_approx=False,\n",
        "        attention_norm_type=\"postnorm\",\n",
        "        name=\"encoder\",\n",
        "    ):\n",
        "        super().__init__(name=name)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_heads = num_heads\n",
        "        self.num_layers = num_layers\n",
        "        self.intermediate_size = intermediate_size\n",
        "        self.num_conv_pos_embeddings = num_conv_pos_embeddings\n",
        "        self.num_conv_pos_embedding_groups = num_conv_pos_embedding_groups\n",
        "        self.survival_prob = survival_prob\n",
        "        self.dropout = dropout\n",
        "        self.layer_norm_eps = layer_norm_eps\n",
        "        self.is_gelu_approx = is_gelu_approx\n",
        "        self.attention_norm_type = attention_norm_type\n",
        "\n",
        "        self.pos_conv_embed = PositionalConvEmbedding(\n",
        "            hidden_size,\n",
        "            num_conv_pos_embeddings,\n",
        "            num_conv_pos_embedding_groups,\n",
        "            is_gelu_approx=is_gelu_approx,\n",
        "            name=\"pos_conv_embed\",\n",
        "        )\n",
        "        self.layer_norm = tf.keras.layers.LayerNormalization(\n",
        "            epsilon=layer_norm_eps, name=\"layer_norm\"\n",
        "        )\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
        "        self.layers = [\n",
        "            TransformerLayer(\n",
        "                hidden_size,\n",
        "                num_heads,\n",
        "                intermediate_size,\n",
        "                survival_prob=survival_prob,\n",
        "                layer_norm_eps=layer_norm_eps,\n",
        "                is_gelu_approx=is_gelu_approx,\n",
        "                dropout=dropout,\n",
        "                attention_norm_type=attention_norm_type,\n",
        "                name=f\"layers/{i}\",\n",
        "            )\n",
        "            for i in range(num_layers)\n",
        "        ]\n",
        "\n",
        "    def call(self, batch, attention_mask=None, training=False):\n",
        "        if attention_mask is not None:\n",
        "            batch = tf.where(attention_mask[:, :, tf.newaxis], batch, 0.0)\n",
        "            seqlen = batch.shape[1]\n",
        "\n",
        "            attention_mask = tf.cast(attention_mask, dtype=batch.dtype)\n",
        "            attention_mask = (1.0 - attention_mask) * tf.constant(-10000.0)\n",
        "\n",
        "            # tf.broadcast_to doesn't work when batch size is unknown (especially with TFSavedModel)\n",
        "            attention_mask = attention_mask[tf.newaxis, :, tf.newaxis, :]\n",
        "            attention_mask = tf.repeat(attention_mask, seqlen, axis=0)\n",
        "            attention_mask = tf.reshape(attention_mask, (seqlen, -1, 1, seqlen))\n",
        "            attention_mask = tf.transpose(attention_mask, perm=[1, 2, 0, 3])\n",
        "\n",
        "        batch = batch + self.pos_conv_embed(batch)\n",
        "\n",
        "        if self.attention_norm_type == \"postnorm\":\n",
        "            batch = self.layer_norm(batch)\n",
        "\n",
        "        batch = self.dropout(batch, training=training)\n",
        "        for layer in self.layers:\n",
        "            batch = layer(batch, attention_mask=attention_mask, training=training)\n",
        "\n",
        "        if self.attention_norm_type == \"prenorm\":\n",
        "            batch = self.layer_norm(batch)\n",
        "        return batch\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"hidden_size\": self.hidden_size,\n",
        "                \"num_heads\": self.num_heads,\n",
        "                \"num_layers\": self.num_layers,\n",
        "                \"intermediate_size\": self.intermediate_size,\n",
        "                \"num_conv_pos_embeddings\": self.num_conv_pos_embeddings,\n",
        "                \"num_conv_pos_embedding_groups\": self.num_conv_pos_embedding_groups,\n",
        "                \"survival_prob\": self.survival_prob,\n",
        "                \"dropout\": self.dropout,\n",
        "                \"layer_norm_eps\": self.layer_norm_eps,\n",
        "                \"is_gelu_approx\": self.is_gelu_approx,\n",
        "                \"attention_norm_type\": self.attention_norm_type,\n",
        "            }\n",
        "        )\n",
        "        return config\n",
        "\n",
        "# from .feature_extractor import FeatureExtractorLayer, FeatureProjection\n",
        "\n",
        "#     FeatureExtractorLayer\n",
        "class FeatureExtractorLayer(tf.keras.layers.Layer):\n",
        "    def __init__(\n",
        "        self,\n",
        "        filter_sizes,\n",
        "        kernal_sizes,\n",
        "        strides,\n",
        "        conv_bias=False,\n",
        "        is_gelu_approx=False,\n",
        "        layer_id=0,\n",
        "        feature_extractor_norm_type=\"group\",\n",
        "        name=None,\n",
        "    ):\n",
        "        super().__init__(name=name)\n",
        "        self.filter_sizes = filter_sizes\n",
        "        self.kernal_sizes = kernal_sizes\n",
        "        self.strides = strides\n",
        "        self.conv_bias = conv_bias\n",
        "        self.is_gelu_approx = is_gelu_approx\n",
        "        self.layer_id = layer_id\n",
        "        self.feature_extractor_norm_type = feature_extractor_norm_type\n",
        "\n",
        "        conv_dim = filter_sizes[layer_id]\n",
        "        kernal_size = kernal_sizes[layer_id]\n",
        "        stride = strides[layer_id]\n",
        "\n",
        "        self.conv_layer = tf.keras.layers.Conv1D(\n",
        "            conv_dim,\n",
        "            kernal_size,\n",
        "            strides=stride,\n",
        "            use_bias=conv_bias,\n",
        "            name=\"conv\",\n",
        "        )\n",
        "\n",
        "        self.layer_norm = None\n",
        "        if self.feature_extractor_norm_type == \"group\":\n",
        "            if layer_id == 0:\n",
        "                self.layer_norm = GroupNormalization(\n",
        "                    conv_dim,\n",
        "                    axis=-1,\n",
        "                    name=\"layer_norm\",\n",
        "                    epsilon=1e-5,\n",
        "                )\n",
        "        elif self.feature_extractor_norm_type == \"layer\":\n",
        "            # TODO: check value of axis\n",
        "            self.layer_norm = tf.keras.layers.LayerNormalization(axis=-1, epsilon=1e-5, name=\"layer_norm\")\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "    def call(self, batch):\n",
        "        batch = self.conv_layer(batch)\n",
        "        if self.layer_norm is not None:\n",
        "            batch = self.layer_norm(batch)\n",
        "        batch = tf.nn.gelu(batch, approximate=self.is_gelu_approx)\n",
        "        return batch\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"filter_sizes\": self.filter_sizes,\n",
        "                \"kernal_sizes\": self.kernal_sizes,\n",
        "                \"strides\": self.strides,\n",
        "                \"conv_bias\": self.conv_bias,\n",
        "                \"is_gelu_approx\": self.is_gelu_approx,\n",
        "                \"layer_id\": self.layer_id,\n",
        "                \"feature_extractor_norm_type\": self.feature_extractor_norm_type,\n",
        "            }\n",
        "        )\n",
        "        return config\n",
        "\n",
        "#   FeatureProjection\n",
        "\n",
        "class FeatureProjection(tf.keras.layers.Layer):\n",
        "    def __init__(\n",
        "        self, hidden_size, layer_norm_eps=1e-5, dropout=0.1, name=\"feature_projection\"\n",
        "    ):\n",
        "        super().__init__(name=name)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.layer_norm_eps = layer_norm_eps\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.layer_norm = tf.keras.layers.LayerNormalization(\n",
        "            epsilon=layer_norm_eps, name=\"layer_norm\"\n",
        "        )\n",
        "        self.projection = tf.keras.layers.Dense(hidden_size, name=\"projection\")\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
        "\n",
        "    def call(self, batch, training=False):\n",
        "        batch = self.layer_norm(batch)\n",
        "        batch = self.projection(batch)\n",
        "        return self.dropout(batch, training=training)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"hidden_size\": self.hidden_size,\n",
        "                \"layer_norm_eps\": self.layer_norm_eps,\n",
        "                \"dropout\": self.dropout,\n",
        "            }\n",
        "        )\n",
        "        return config\n",
        "\n",
        "# from .spec_augment import apply_spec_augmentation\n",
        "\n",
        "def apply_spec_augmentation(features, masked_spec_augment, mask_prob, mask_length):\n",
        "    \"\"\"\n",
        "    This method apply spec-augmentation to the `hidden_states`\n",
        "    Args:\n",
        "        features (:obj: `tf.Tensor`) of shape (batch_size, seqlen, hidden_size):\n",
        "            hidden states which we want to mask.\n",
        "        masked_spec_augment (:obj: `tf.Tensor`) of shape (hidden_states,):\n",
        "            replace indices to be masked with these values.\n",
        "        mask_prob (:obj: `float`):\n",
        "            probability if certain token should be masked, this decides number of tokens to be masked.\n",
        "        mask_length (:obj: `int`):\n",
        "            span length of the tokens to be masked.\n",
        "    Return:\n",
        "        features (:obj: `tf.Tensor`) of shape (batch_size, seqlen, hidden_size):\n",
        "            hidden states masked at certain positions which are chosen randomly.\n",
        "    \"\"\"\n",
        "\n",
        "    # first find the indices to mask from the sequence\n",
        "    # choose mask such that we conserve the mask_length\n",
        "    mask_indices = _compute_mask_indices(\n",
        "        features.shape[:2], mask_prob, mask_length, min_masks=2\n",
        "    )\n",
        "\n",
        "    # since we are going to `tf.where(...)`, we need True at positions where we want to mask\n",
        "    # while False at indices which we don't want to change\n",
        "    mask_indices = tf.cast(mask_indices[:, :, None], tf.bool)\n",
        "\n",
        "    # It's important to keep dtype of masked_spec_augment & features same\n",
        "    # since we are going to accomodate both in a single tensor\n",
        "    masked_spec_augment = tf.cast(masked_spec_augment, features.dtype)[None, None, :]\n",
        "\n",
        "    # simply call `tf.where(...)`, and replace True positions (chosen randomly)\n",
        "    # with trainable weights (i.e. masked_spec_augment)\n",
        "    features = tf.where(mask_indices, masked_spec_augment, features)\n",
        "    return features\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class TFKerasModel(tf.keras.Model):\n",
        "    def save_pretrained(self, save_dir):\n",
        "        \"\"\"\n",
        "        This method will save model weights and config in `save_directory`.\n",
        "        \"\"\"\n",
        "        self.config.save_pretrained(save_dir)\n",
        "        self.save_weights(os.path.join(save_dir, \"tf_model.h5\"))\n",
        "\n",
        "    def push_to_hub(self, directory: str, model_id: str):\n",
        "        \"\"\"\n",
        "        Use this method to push your model weights to HuggingFace Hub.\n",
        "        Args:\n",
        "            directory (:obj: `str`):\n",
        "                directory where model weights are prensent.\n",
        "            model_id (:obj: `str`):\n",
        "                Name of the repositary in HuggingFace Hub you want to push to.\n",
        "        \"\"\"\n",
        "        return ModelHubMixin.push_to_hub(directory, model_id=model_id)\n",
        "\n",
        "    @classmethod\n",
        "    def from_pretrained(cls, model_id, **config_kwargs) -> tf.keras.Model:\n",
        "        \"\"\"\n",
        "        This will load model weights from the dictionary specified or download it from HuggingFace Hub\n",
        "        if weights are not available locally.\n",
        "        Args:\n",
        "            model_id (:obj: `str`):\n",
        "                Directory where weights are present or model_id if needs to be downloaded from HuggingFace Hub.\n",
        "            config_kwargs (:obj: `dict`)\n",
        "                Extra arguments will be passed to `Wav2Vec2Config`.\n",
        "        Returns:\n",
        "            Instance of `tf.keras.Model` initialized from trained weights.\n",
        "        \"\"\"\n",
        "\n",
        "        save_dir = model_id\n",
        "        if not os.path.isdir(save_dir):\n",
        "            os.makedirs(save_dir, exist_ok=True)\n",
        "            config_url = f\"wget https://huggingface.co/{model_id}/resolve/main/config.json -P {save_dir}\"\n",
        "            model_url = f\"wget https://huggingface.co/{model_id}/resolve/main/tf_model.h5 -P {save_dir}\"\n",
        "\n",
        "            print(\n",
        "                f\"Downloading model weights from https://huggingface.co/{model_id} ... \",\n",
        "                end=\"\",\n",
        "            )\n",
        "            try:\n",
        "                for url in [config_url, model_url]:\n",
        "                    subprocess.run(url.split(), check=True, stderr=subprocess.PIPE)\n",
        "            except:\n",
        "                raise ValueError(\n",
        "                    f\"Couldn't download model weights from https://huggingface.co/{model_id}\"\n",
        "                )\n",
        "            print(\"Done\")\n",
        "        else:\n",
        "            print(f\"Loading weights locally from `{save_dir}`\")\n",
        "\n",
        "        input_shape = config_kwargs.pop(\"input_shape\", (1, 2048))\n",
        "        config = Wav2Vec2Config.from_json(os.path.join(save_dir, \"config.json\"))\n",
        "        config = replace(config, **config_kwargs)\n",
        "        model = cls(config, input_shape=input_shape)\n",
        "        model.load_weights(os.path.join(save_dir, \"tf_model.h5\"))\n",
        "        print(\"Total number of loaded variables:\", len(model.variables))\n",
        "        return model\n",
        "\n",
        "    def _init(self, input_shape=None, is_robust=False, for_export=False):\n",
        "        \"\"\"Build Model weights using dummy inputs\"\"\"\n",
        "        # call this at the end only\n",
        "        if input_shape is None:\n",
        "            input_shape = (1, 2048)\n",
        "        dummy_input = tf.ones(input_shape, dtype=tf.float32)\n",
        "        attention_mask = tf.ones(input_shape) if is_robust else None\n",
        "\n",
        "        if for_export:\n",
        "            self((dummy_input, attention_mask))\n",
        "        else:\n",
        "            try:\n",
        "                # this operation doesn't work on CPU\n",
        "                self.predict(dummy_input, attention_mask=attention_mask)\n",
        "            except:\n",
        "                # this operation will hang the TPU VM, hence prefer `.predict`\n",
        "                self(dummy_input, attention_mask=attention_mask)\n",
        "\n",
        "\n",
        "class Wav2Vec2Model(TFKerasModel):\n",
        "    def __init__(self, config: Wav2Vec2Config, input_shape=(1, 246000), name=\"wav2vec2\"):\n",
        "        super().__init__(name=name)\n",
        "        if not isinstance(config, Wav2Vec2Config):\n",
        "            raise ValueError(\"`config` must be an instace of `Wave2Vec2Config`\")\n",
        "\n",
        "        self.config = config\n",
        "        self.hidden_size = config.hidden_size\n",
        "        self.is_robust = config.is_robust\n",
        "        self.kernal_sizes = config.kernal_sizes\n",
        "        self.strides = config.strides\n",
        "\n",
        "        # spec-augmentation\n",
        "        self.apply_spec_augment = config.apply_spec_augment\n",
        "        self.mask_time_prob = config.mask_time_prob\n",
        "        self.mask_time_length = config.mask_time_length\n",
        "\n",
        "        num_feature_extractor_layers = len(config.filter_sizes)\n",
        "\n",
        "        self.feature_extractor = [\n",
        "            FeatureExtractorLayer(\n",
        "                config.filter_sizes,\n",
        "                config.kernal_sizes,\n",
        "                config.strides,\n",
        "                conv_bias=config.conv_bias,\n",
        "                is_gelu_approx=config.is_gelu_approx,\n",
        "                feature_extractor_norm_type=config.feature_extractor_norm_type,\n",
        "                layer_id=i,\n",
        "                name=f\"feature_extractor/conv_layers/{i}\",\n",
        "            )\n",
        "            for i in range(num_feature_extractor_layers)\n",
        "        ]\n",
        "        self.feature_projection = FeatureProjection(\n",
        "            config.hidden_size,\n",
        "            layer_norm_eps=config.layer_norm_eps,\n",
        "            dropout=config.dropout,\n",
        "            name=\"feature_projection\",\n",
        "        )\n",
        "        self.encoder = Wav2Vec2Encoder(\n",
        "            config.hidden_size,\n",
        "            config.num_heads,\n",
        "            config.num_layers,\n",
        "            config.intermediate_size,\n",
        "            config.num_conv_pos_embeddings,\n",
        "            config.num_conv_pos_embedding_groups,\n",
        "            survival_prob=config.survival_prob,\n",
        "            dropout=config.dropout,\n",
        "            layer_norm_eps=config.layer_norm_eps,\n",
        "            is_gelu_approx=config.is_gelu_approx,\n",
        "            attention_norm_type=config.attention_norm_type,\n",
        "            name=\"encoder\",\n",
        "        )\n",
        "\n",
        "        if input_shape is not None:\n",
        "            self._init(input_shape=input_shape, is_robust=config.is_robust)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.masked_spec_augment = self.add_weight(\n",
        "            name=\"masked_spec_embed\",\n",
        "            shape=(self.hidden_size,),\n",
        "            initializer=\"uniform\",\n",
        "            trainable=True,\n",
        "        )\n",
        "\n",
        "    def call(self, batch, attention_mask: Optional[tf.Tensor] = None, training=False):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            batch (:obj: `tf.Tensor`) of shape (batch_size, seqlen):\n",
        "                Sound tensor obtained from `Wav2Vec2Processor.__call__`.\n",
        "            attention_mask (:obj: `tf.Tensor`, `optional`) of shape (batch_size, seqlen):\n",
        "                Don't pass `attention_mask` when working with checkpoints based on `wav2vec2-base`\n",
        "                otherwise you should pass this argument.\n",
        "            training (:obj: `bool`, `optional`):\n",
        "                Whether to use model for training.\n",
        "        Returns:\n",
        "            Logits from the model of shape (batch_size, seqlen, hidden_dim).\n",
        "        \"\"\"\n",
        "        if self.is_robust and attention_mask is None:\n",
        "            logger.warning(\"You should pass `attention_mask` when working with Wav2Vec2 new checkpoints\")\n",
        "        elif not self.is_robust and attention_mask is not None:\n",
        "            logger.warning(\"You should not pass `attention_mask` when working with checkpoints based on `wav2vec2-base`\")\n",
        "\n",
        "        batch = tf.expand_dims(batch, axis=-1)\n",
        "        for feature_extractor_layer in self.feature_extractor:\n",
        "            batch = feature_extractor_layer(batch)\n",
        "        batch = self.feature_projection(batch, training=training)\n",
        "\n",
        "        if training and self.apply_spec_augment:\n",
        "            batch = apply_spec_augmentation(\n",
        "                batch,\n",
        "                self.masked_spec_augment,\n",
        "                self.mask_time_prob,\n",
        "                self.mask_time_length,\n",
        "            )\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            input_length = tf.reduce_sum(attention_mask, axis=-1)\n",
        "            for kernal_size, stride in zip(self.kernal_sizes, self.strides):\n",
        "                input_length = 1 + (input_length - kernal_size) // stride\n",
        "\n",
        "            attention_mask = tf.sequence_mask(input_length, maxlen=batch.shape[1])\n",
        "\n",
        "        batch = self.encoder(batch, attention_mask=attention_mask, training=training)\n",
        "        return batch\n",
        "\n",
        "    def freeze_feature_extractor(self):\n",
        "        \"\"\"This will freeze the feature extractor layers (Recommended to use for fine-tuning).\"\"\"\n",
        "        for i in range(len(self.feature_extractor)):\n",
        "            self.feature_extractor[i].trainable = False\n",
        "\n",
        "\n",
        "class Wav2Vec2ForCTC(TFKerasModel):\n",
        "    \"\"\"Wave2Vec2 model with a CTC head.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, config: Wav2Vec2Config, input_shape=(1, 246000), name=\"wav2vec2-ctc\"\n",
        "    ):\n",
        "        super().__init__(name=name)\n",
        "        if not isinstance(config, Wav2Vec2Config):\n",
        "            raise ValueError(\"`config` must be an instace of `Wave2Vec2Config`.\")\n",
        "        self.config = config\n",
        "        self.pad_id = config.pad_id\n",
        "\n",
        "        self.model = Wav2Vec2Model(config, input_shape=None, name=\"wav2vec2\")\n",
        "        self.dropout = tf.keras.layers.Dropout(config.dropout)\n",
        "        self.lm_head = tf.keras.layers.Dense(config.vocab_size, name=\"lm_head\")\n",
        "\n",
        "        self._init(input_shape=input_shape, is_robust=config.is_robust)\n",
        "\n",
        "    def freeze_feature_extractor(self):\n",
        "        \"\"\"This will freeze the feature extractor layers (Recommended to use for fine-tuning).\"\"\"\n",
        "        self.model.freeze_feature_extractor()\n",
        "\n",
        "    def call(self, batch: tf.Tensor, attention_mask: Optional[tf.Tensor] = None, training=False):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            batch (:obj: `tf.Tensor`) of shape (batch_size, seqlen):\n",
        "                Sound tensor obtained from `Wav2Vec2Processor.__call__`.\n",
        "            attention_mask (:obj: `tf.Tensor`, `optional`) of shape (batch_size, seqlen):\n",
        "                Don't pass `attention_mask` when working with checkpoints based on `wav2vec2-base`\n",
        "                otherwise you should pass this argument.\n",
        "            training (:obj: `bool`, `optional`):\n",
        "                Whether to use model for training.\n",
        "        Returns:\n",
        "            Logits from the model of shape (batch_size, seqlen, vocab_size).\n",
        "        \"\"\"\n",
        "        batch = self.model(batch, attention_mask=attention_mask, training=training)\n",
        "        batch = self.dropout(batch, training=training)\n",
        "        batch = self.lm_head(batch)\n",
        "        return batch"
      ],
      "metadata": {
        "id": "pwtGlrvmoPQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#                   processor.py\n",
        "\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "import subprocess\n",
        "from itertools import groupby\n",
        "\n",
        "class Wav2Vec2Processor:\n",
        "    def __init__(\n",
        "        self, is_tokenizer, do_normalize=True, vocab_path=\"./vocab.json\"\n",
        "    ):\n",
        "        # whether to use as `feature_extractor` or `tokenizer`\n",
        "\n",
        "        self.is_tokenizer = is_tokenizer\n",
        "        self.do_normalize = do_normalize\n",
        "        self.vocab_path = vocab_path\n",
        "\n",
        "        if self.is_tokenizer:\n",
        "            self._setup_vocab()\n",
        "\n",
        "            self.token_to_id_mapping = self.get_vocab()\n",
        "            self.id_to_token_mapping = {\n",
        "                v: k for k, v in self.token_to_id_mapping.items()\n",
        "            }\n",
        "            self.unk_token = \"<unk>\"\n",
        "            self.unk_id = self.token_to_id_mapping[self.unk_token]\n",
        "\n",
        "            self.dimiliter_token = \"|\"\n",
        "            self.dimiliter_id = self.token_to_id_mapping[self.dimiliter_token]\n",
        "\n",
        "            special_tokens = [\"<pad>\"]\n",
        "            self.special_ids = [self.token_to_id_mapping[k] for k in special_tokens]\n",
        "\n",
        "    def _setup_vocab(self):\n",
        "        \"\"\"This method will download & setup the vocab file if it's not on the `vocab_path`\"\"\"\n",
        "        if not os.path.isfile(self.vocab_path):\n",
        "            url = \"https://github.com/vasudevgupta7/gsoc-wav2vec2/raw/main/data/vocab.json\"\n",
        "\n",
        "            print(f\"Downloading `vocab.json` from {url} ... \", end=\"\")\n",
        "            try:\n",
        "                subprocess.run(\n",
        "                    [\"wget\", url], stdout=subprocess.PIPE, stderr=subprocess.PIPE\n",
        "                )\n",
        "            except:\n",
        "                raise ValueError(f\"Couldn't download `vocab.json` from {url}\")\n",
        "            print(\"DONE\")\n",
        "\n",
        "            self.vocab_path = \"./vocab.json\"\n",
        "\n",
        "    def __call__(self, input_values):\n",
        "        \"\"\"\n",
        "        if is_tokenizer:\n",
        "            input_values (:obj: `str`):\n",
        "                Single string you want to encode to ids\n",
        "        else:\n",
        "            input_values (:obj: `tf.Tensor`):\n",
        "                Tensor which needs to be fed into `model.call()`\n",
        "        \"\"\"\n",
        "        if self.is_tokenizer:\n",
        "            input_values = self._tokenize(input_values)\n",
        "            input_values = [\n",
        "                self.token_to_id_mapping.get(k, self.unk_id) for k in input_values\n",
        "            ]\n",
        "        else:\n",
        "            if self.do_normalize:\n",
        "                input_values = self._normalize(input_values)\n",
        "        return input_values\n",
        "\n",
        "    def decode(self, input_ids: list, skip_special_tokens=True, group_tokens=True):\n",
        "        \"\"\"\n",
        "        Use this method to decode your ids back to string.\n",
        "        Args:\n",
        "            input_ids (:obj: `list`):\n",
        "                input_ids you want to decode to string.\n",
        "            skip_special_tokens (:obj: `bool`, `optional`):\n",
        "                Whether to remove special tokens (like `<pad>`) from string.\n",
        "            group_tokens (:obj: `bool`, `optional`):\n",
        "                Whether to group repeated characters.\n",
        "        \"\"\"\n",
        "        if group_tokens:\n",
        "            input_ids = [t[0] for t in groupby(input_ids)]\n",
        "        if skip_special_tokens:\n",
        "            input_ids = [k for k in input_ids if k not in self.special_ids]\n",
        "        tokens = [self.id_to_token_mapping.get(k, self.unk_token) for k in input_ids]\n",
        "        tokens = [k if k != self.dimiliter_token else \" \" for k in tokens]\n",
        "        return \"\".join(tokens).strip()\n",
        "\n",
        "    def _tokenize(self, string: str):\n",
        "        string = re.sub(\"-\", \" \", string)\n",
        "        string = re.sub(\"[^A-Z' ]\", \"\", string.upper())\n",
        "        return list(string.replace(\" \", self.dimiliter_token))\n",
        "\n",
        "    def get_vocab(self):\n",
        "        with open(self.vocab_path, \"r\") as f:\n",
        "            vocab = json.load(f)\n",
        "        return vocab\n",
        "\n",
        "    def _normalize(self, x):\n",
        "        \"\"\"You must call this before padding.\"\"\"\n",
        "        # -> (1, seqlen)\n",
        "        mean = tf.reduce_mean(x, axis=-1, keepdims=True)\n",
        "        var = tf.math.reduce_variance(x, axis=-1, keepdims=True)\n",
        "        return tf.squeeze((x - mean) / tf.sqrt(var + 1e-5))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    \"\"\"Testing Area\"\"\"\n",
        "\n",
        "    feature_extractor = Wav2Vec2Processor(is_tokenizer=False)\n",
        "    batch, _ = tf.audio.decode_wav(tf.io.read_file(\"../data/sample.wav\"))\n",
        "    batch = tf.transpose(batch, perm=(1, 0))\n",
        "    batch = tf.concat([batch, batch], axis=0)\n",
        "\n",
        "    out = feature_extractor(batch)\n",
        "    print(out)\n",
        "\n",
        "    print(\"\\n\\n\")\n",
        "\n",
        "    tokenizer = Wav2Vec2Processor(is_tokenizer=True)\n",
        "    ids = tokenizer(\"vasudev guptaa is a data scientist.\")\n",
        "    print(ids)\n",
        "    print(tokenizer.decode(ids))\n",
        "    print(tokenizer.decode(ids, group_tokens=False))\n",
        "\n",
        "    ids = tokenizer(\"how is life gooing? what's up.. yayy i got results. it's awe-some\")\n",
        "    print(ids)\n",
        "    print(tokenizer.decode(ids))\n",
        "    print(tokenizer.decode(ids, group_tokens=False))"
      ],
      "metadata": {
        "id": "w9M0cErA02UP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.getcwd()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PMq8j__kGJ-n",
        "outputId": "95d75e30-be13-45e9-f015-6b0d1203b9bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "-uECUZ2E4bjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -q git+https://github.com/vasudevgupta7/gsoc-wav2vec2@main\n",
        "!sudo apt-get install -y libsndfile1-dev\n",
        "!pip3 install -q SoundFile"
      ],
      "metadata": {
        "id": "b8QMFX6vSX1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -q git+https://github.com/vasudevgupta7/gsoc-wav2vec2@main"
      ],
      "metadata": {
        "id": "Qd9eCN27DKE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "from dataclasses import asdict, dataclass, field\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Wav2Vec2Config:\n",
        "    vocab_size: int = 32\n",
        "    dropout: int = 0.1\n",
        "    hidden_size: int = 768\n",
        "    num_heads: int = 12\n",
        "    num_layers: int = 12\n",
        "    intermediate_size: int = 3072\n",
        "    is_gelu_approx: bool = False\n",
        "    layer_norm_eps: float = 1e-5\n",
        "    survival_prob: float = 1.0\n",
        "    pad_id: int = 0\n",
        "\n",
        "    # positional embedding\n",
        "    num_conv_pos_embeddings: int = 128\n",
        "    num_conv_pos_embedding_groups: int = 16\n",
        "\n",
        "    # feature extractor\n",
        "    filter_sizes: list = field(\n",
        "        default_factory=lambda: [512, 512, 512, 512, 512, 512, 512]\n",
        "    )\n",
        "    kernal_sizes: list = field(default_factory=lambda: [10, 3, 3, 3, 3, 2, 2])\n",
        "    strides: list = field(default_factory=lambda: [5, 2, 2, 2, 2, 2, 2])\n",
        "    conv_bias: bool = False\n",
        "\n",
        "    # spec augmentation arguments\n",
        "    apply_spec_augment: bool = True\n",
        "    mask_time_prob: float = 0.05\n",
        "    mask_time_length: int = 10\n",
        "\n",
        "    attention_norm_type: str = \"postnorm\"\n",
        "    feature_extractor_norm_type: bool = \"group\"\n",
        "    is_robust: bool = False\n",
        "\n",
        "    def __post_init__(self):\n",
        "        if not (len(self.filter_sizes) == len(self.kernal_sizes) == len(self.strides)):\n",
        "            raise ValueError(\n",
        "                \"Length of filter_sizes, kernal_sizes, strides must match.\"\n",
        "            )\n",
        "        if self.hidden_size % self.num_heads != 0:\n",
        "            raise ValueError(\"Hidden size must be perfect multiple of num_heads.\")\n",
        "\n",
        "        assert self.feature_extractor_norm_type in [\"group\", \"layer\"], \"Only `group` / `layer` are supported\"\n",
        "        assert self.attention_norm_type in [\"prenorm\", \"postnorm\"], \"Only `prenorm` / `postnorm` are supported\"\n",
        "\n",
        "    def save_pretrained(self, save_dir):\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "        with open(os.path.join(save_dir, \"config.json\"), \"w\") as f:\n",
        "            json.dump(asdict(self), f)\n",
        "\n",
        "    @classmethod\n",
        "    def from_json(cls, path: str):\n",
        "        with open(path, \"r\") as f:\n",
        "            config_dict = json.load(f)\n",
        "        return cls(**config_dict)\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class RobustWav2Vec2Config(Wav2Vec2Config):\n",
        "    attention_norm_type: str = \"prenorm\"\n",
        "    feature_extractor_norm_type: str = \"layer\"\n",
        "    is_robust: bool = True\n",
        "    conv_bias: bool = True\n",
        "\n",
        "    hidden_size: int = 1024\n",
        "    intermediate_size: int = 4096\n",
        "    num_heads: int = 16\n",
        "    num_layers: int = 24"
      ],
      "metadata": {
        "id": "Csla3bqvTDGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "!pip3 install tensorflow==2.7.0\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "print(\"TF version\", tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRIBTbL-TuCF",
        "outputId": "d7cce7d1-9415-48dd-db29-27bdca375244"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.7.0 in /usr/local/lib/python3.7/dist-packages (2.7.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.13.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.1.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (2.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (0.2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (0.37.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (2.7.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.0.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.6.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.21.5)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (2.7.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (3.17.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (0.24.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (13.0.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.43.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (3.10.0.2)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (0.4.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.15.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (2.8.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow==2.7.0) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (0.4.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (57.4.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (3.3.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.7.0) (4.11.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.7.0) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.0) (3.2.0)\n",
            "TF version 2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile"
      ],
      "metadata": {
        "id": "hYxPyVFBUF6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with ZipFile('drive/MyDrive/ezyZip.zip', 'r') as zipObj:\n",
        "  zipObj.extractall('drive/MyDrive/test')"
      ],
      "metadata": {
        "id": "E1hk2n6Wke6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -q git+https://github.com/vasudevgupta7/gsoc-wav2vec2@main\n",
        "!sudo apt-get install -y libsndfile1-dev\n",
        "!pip3 install -q SoundFile"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLxvRstXoiV2",
        "outputId": "53fb6818-6c40-42e4-e7cd-867eeec00bf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.7 MB 11.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 67 kB 4.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 50 kB 5.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 50.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 181 kB 53.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n",
            "\u001b[?25h  Building wheel for wav2vec2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libsndfile1-dev is already the newest version (1.0.28-4ubuntu0.18.04.2).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-470\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from wav2vec2 import Wav2Vec2Config\n",
        "\n",
        "config = Wav2Vec2Config()\n",
        "\n",
        "print(\"TF version:\", tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HN0qCFHTprXV",
        "outputId": "de81a101-d7df-4038-b703-2caba394990b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.7.0\n",
            "  Downloading tensorflow-2.7.0-cp37-cp37m-manylinux2010_x86_64.whl (489.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 489.6 MB 13 kB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (0.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.15.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (0.24.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.44.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.0.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (3.17.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.13.3)\n",
            "Collecting keras<2.8,>=2.7.0rc0\n",
            "  Downloading keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 43.3 MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<2.8,~=2.7.0rc0\n",
            "  Downloading tensorflow_estimator-2.7.0-py2.py3-none-any.whl (463 kB)\n",
            "\u001b[K     |████████████████████████████████| 463 kB 4.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.6.3)\n",
            "Collecting gast<0.5.0,>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.21.5)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (3.10.0.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.1.2)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (13.0.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (0.37.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.1.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (2.8.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow==2.7.0) (1.5.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (3.3.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (0.4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.7.0) (4.11.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.7.0) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.0) (3.2.0)\n",
            "Installing collected packages: tensorflow-estimator, keras, gast, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.0\n",
            "    Uninstalling tensorflow-2.8.0:\n",
            "      Successfully uninstalled tensorflow-2.8.0\n",
            "Successfully installed gast-0.4.0 keras-2.7.0 tensorflow-2.7.0 tensorflow-estimator-2.7.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gast",
                  "keras",
                  "tensorflow",
                  "tensorflow_estimator"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF version: 2.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_layer = hub.KerasLayer(\"https://tfhub.dev/vasudevgupta7/wav2vec2/1\", trainable=True)"
      ],
      "metadata": {
        "id": "v1kE02wzVw87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUDIO_MAXLEN = 246000\n",
        "LABEL_MAXLEN = 256\n",
        "BATCH_SIZE = 2"
      ],
      "metadata": {
        "id": "ocH5trvbWA86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow_hub import keras_layer"
      ],
      "metadata": {
        "id": "YxzQsNF22Dbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.Input(shape=(AUDIO_MAXLEN,))\n",
        "hidden_states = pretrained_layer(inputs)\n",
        "outputs = tf.keras.layers.Dense(Wav2Vec2Config.vocab_size)(hidden_states)\n",
        "\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "metadata": {
        "id": "e4IvvtLe2BoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model(tf.random.uniform(shape=(BATCH_SIZE, AUDIO_MAXLEN)))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "IeCru-8Z2Ehk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#                      Tensorflow.com      it is tikenization on text_to_sequences\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "71AKGtxw14Fd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "             'I love my dog',\n",
        "             'I love my cat',\n",
        "             'You love my dog!',\n",
        "             'Do you think my dog is amazing?',\n",
        "             'i am not that it is best way to find out it'\n",
        "]\n",
        "data_dir = \"/content/drive/MyDrive/rus.json/\"\n",
        "all_files = os.listdir(data_dir)\n",
        "\n",
        "json_files = [f for f in all_files if f.endswith(\".json\")]\n",
        "\n",
        "print(\"Transcription files:\", json_files)\n"
      ],
      "metadata": {
        "id": "8mXb5af17V-u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "657524ac-7fc4-4276-9ea5-8e3c24e12674"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotADirectoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-b28fc4c547c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m ]\n\u001b[1;32m      8\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/rus.json/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mall_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mjson_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_files\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: '/content/drive/MyDrive/rus.json/'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words = 100, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "word_index = tokenizer.word_index\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "\n",
        "test_seq = tokenizer.texts_to_sequences(test_data)\n",
        "\n",
        "padded = pad_sequences(sequences)\n",
        "\n",
        "padded1 = pad_sequences(sequences, padding = 'post', truncating = 'post', maxlen = 5)"
      ],
      "metadata": {
        "id": "CzemINO39aSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_index)\n",
        "\n",
        "print(sequences)\n",
        "\n",
        "print(padded)\n",
        "\n",
        "print(padded1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Hpbrn0C-A5N",
        "outputId": "b16b07d8-92cb-4607-aae5-70c17e451a9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<OOV>': 1, 'my': 2, 'i': 3, 'love': 4, 'dog': 5, 'you': 6, 'is': 7, 'it': 8, 'cat': 9, 'do': 10, 'think': 11, 'amazing': 12, 'am': 13, 'not': 14, 'that': 15, 'best': 16, 'way': 17, 'to': 18, 'find': 19, 'out': 20}\n",
            "[[3, 4, 2, 5], [3, 4, 2, 9], [6, 4, 2, 5], [10, 6, 11, 2, 5, 7, 12], [3, 13, 14, 15, 8, 7, 16, 17, 18, 19, 20, 8]]\n",
            "[[ 0  0  0  0  0  0  0  0  3  4  2  5]\n",
            " [ 0  0  0  0  0  0  0  0  3  4  2  9]\n",
            " [ 0  0  0  0  0  0  0  0  6  4  2  5]\n",
            " [ 0  0  0  0  0 10  6 11  2  5  7 12]\n",
            " [ 3 13 14 15  8  7 16 17 18 19 20  8]]\n",
            "[[ 3  4  2  5  0]\n",
            " [ 3  4  2  9  0]\n",
            " [ 6  4  2  5  0]\n",
            " [10  6 11  2  5]\n",
            " [ 3 13 14 15  8]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open(\"./drive/MyDrive/rus.json\", 'r') as f:\n",
        "  datastore = json.load(f)\n",
        "\n",
        "sentences =   []\n",
        "labels = []\n",
        "urls = []\n",
        "\n"
      ],
      "metadata": {
        "id": "ay9bDx7qHKOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "Rh9HVxXM3dsG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "padded = pad_sequences(sequences, padding='post')\n",
        "print(padded[0])\n",
        "print(padded.shape)"
      ],
      "metadata": {
        "id": "tR0fVBx0TJ9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_sentences = sentences[0:training_size]\n",
        "testing"
      ],
      "metadata": {
        "id": "MCM9_eswnPuj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}